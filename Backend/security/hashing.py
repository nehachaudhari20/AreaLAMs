# -*- coding: utf-8 -*-
"""Database.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lnPl3h4VMaWnFQzmyhejqrK0IhzDikiu
"""

import json
import hashlib
import psycopg2

# --- Load JSON file ---
with open('lamx_dataset.json') as f:
    data_list = json.load(f)

# --- Hashing function ---
def hash_field(value):
    return hashlib.sha256(value.encode()).hexdigest()[:12]

# --- Connect to PostgreSQL ---
conn = psycopg2.connect(
    host="localhost",
    dbname="AREALIS_DATABASE",
    user="postgres",
    password="123@SITPune"
)
cur = conn.cursor()

# --- Insert each record ---
for data in data_list:
    hashed_txn_id = hash_field(data["txn_id"])
    hashed_acc_no = hash_field(data["acc_no"])

    cur.execute("""
        INSERT INTO logs (
            hashed_txn_id, hashed_acc_no, status, amount,
            gateway, region, service, trace_id, span_id,
            error_code, latency_ms, cpu, memory_usage,
            error_count, total_requests, timestamp
        )
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (hashed_txn_id) DO NOTHING;
    """, (
        hashed_txn_id,
        hashed_acc_no,
        data["status"],
        data["amount"],
        data["gateway"],
        data["region"],
        data["service"],
        data["trace_id"],
        data["span_id"],
        data["error_code"],
        data["latency_ms"],
        data["CPU"],
        data["memory_usage"],
        data["error_count"],
        data["total_requests"],
        data["timestamp"]
    ))

# --- Commit and close ---
conn.commit()
cur.close()
conn.close()

print("âœ… Data inserted successfully!")